# 뱅샐

## 데이터 분석 환경

- Amazon S3

- Glue

- Spark (on EMR)

## 분석 대상 데이터 소스

- 프로덕션 데이터베이스 스냅샷

- 사용자 이벤트

→ 

## 업무 1. Data base에 저장된 데이터를 Data Warehouse로 옮기는 일 (ETL)

데이터 베이스에서 쿼리 실행하면 연산이 복잡한 경우에 서비스가 정상적으로 실행되지 않을 수 있음 

- 데이터 분석에 특화된 데이터 베이스인 데이터 웨어하우스에서 연산을 주로 수행함

- aws의 redshift, snowflake 등이 있다

## ETL

Extract

- 데이터를 추출

- 서비스의 database, 앱/웹의 로그데이터 추출

Transform

- json파일의 데이터를 row, col이 있는엑셀 등으로 변환하는 것

Load

- 변환한 데이터를 데이터 웨어하우스에 로드 해야함

## 데이터 처리 방식

1. 배치 (Batch)

    : 특정 시간단위로 1번씩 주기적으로 실행

2. 실시간 (Realtime, Straming)

    : 요청시 바로, 실시간으로 데이터 처리

---

## 업무 2. 데이터 분석을 쉽게 할 수 있는 인프라 구축

- 데이터 마트 구축
  
  - SQL Join한 결과를 Batch로 Table에 저장하는 것
  
  - 데이터 웨어하우스에서 데이터 목적에 맞게 데이터 마트를 구축해줌!

- 데이터 마트와 시각화 도구를 결합하는 환경을 마련
  
  - BI (Business Intelligence) 도구나 태블로 활용

---

## 업무 3. Data Product 개발

- 사내 구성원들을 위한 Data  관련 제품 및 서비스 개발
  
  - A/B Test Platform
  
  - 구글 애널리틱스같은 분석 도구
  
  - 데이터 로그 시스템
  
  - 머신/딥러닝 서비스

---

## 대표 라이브러리

- Spark, Kafka : 대용량 데이터 처리, 실시간 처리

- Airflow : Workflow 관리

- 상황에 따라 도구를 선택하는 것이 중요 : 상황과 목적에 따라 적절히 선택하는 역량 
  
  - 왜 그 도구를 선택했는지 설명할 수 있는 것
  
  - 예) 우리 프로젝트에는 kafka보다 kinesis가 ~이유때문에 더 적합해서 kinesis를 사용했다. 
